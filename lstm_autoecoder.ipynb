{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder:\n",
    "    def __init__(self, timesteps=10, features=18):\n",
    "        self.timesteps = timesteps\n",
    "        self.features = features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.threshold = None  \n",
    "\n",
    "    def create_sequences(self, data):\n",
    "        \"\"\"Creates overlapping sequences from data\"\"\"\n",
    "        sequences = [data[i:i + self.timesteps] for i in range(len(data) - self.timesteps + 1)]\n",
    "        return np.array(sequences)\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Defines the LSTM autoencoder architecture\"\"\"\n",
    "        inputs = keras.Input(shape=(self.timesteps, self.features))\n",
    "        x = layers.LSTM(24, activation='tanh', return_sequences=True)(inputs)\n",
    "        encoded = layers.LSTM(6, activation='tanh', return_sequences=False)(x)\n",
    "        x = layers.RepeatVector(self.timesteps)(encoded)\n",
    "        x = layers.LSTM(6, activation='tanh', return_sequences=True)(x)\n",
    "        x = layers.LSTM(24, activation='tanh', return_sequences=True)(x)\n",
    "        decoded = layers.TimeDistributed(layers.Dense(self.features))(x)\n",
    "\n",
    "        model = keras.Model(inputs, decoded)\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        return model  \n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\"Scales and converts data into sequences\"\"\"\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.values\n",
    "        data = self.scaler.fit_transform(data)\n",
    "        return self.create_sequences(data)\n",
    "\n",
    "    def train(self, data, epochs=50, batch=64, val_split=0.2):\n",
    "        \"\"\"Trains the LSTM autoencoder\"\"\"\n",
    "        X = self.preprocess(data)\n",
    "        X_train, X_val = train_test_split(X, test_size=val_split, shuffle=False)\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        start = time.time()\n",
    "        history = self.model.fit(X_train, X_train, \n",
    "            epochs=epochs, batch_size=batch,\n",
    "            validation_data=(X_val, X_val), \n",
    "            callbacks=[early_stop], shuffle=True)\n",
    "        print(f\"Training Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "        # Compute threshold dynamically without the typical \"mean + 3*std\"\n",
    "        val_errors = np.abs(self.model.predict(X_val) - X_val).mean(axis=(1, 2))\n",
    "        self.threshold = np.percentile(val_errors, 95)  \n",
    "\n",
    "        # Plot training loss\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def detect(self, data):\n",
    "        \"\"\"Detects anomalies\"\"\"\n",
    "        if self.model is None or self.threshold is None:\n",
    "            raise RuntimeError(\"Train the model first.\")\n",
    "        \n",
    "        sequences = self.preprocess(data)\n",
    "        errors = np.abs(self.model.predict(sequences) - sequences).mean(axis=(1, 2))\n",
    "        return errors > self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filepath, columns):\n",
    "    \"\"\"Loads CSV and extracts required columns\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File {filepath} not found.\")\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    return df[columns] if set(columns).issubset(df.columns) else None\n",
    "\n",
    "NORMAL_DATA_PATH = '/normal_data.csv'\n",
    "ANOMALY_DATA_PATH = '/anomaly_data.csv'\n",
    "\n",
    "feature_columns = [\n",
    "    f'actual_q_{i}' for i in range(6)] + \\\n",
    "    [f'actual_qd_{i}' for i in range(6)] + \\\n",
    "    [f'actual_current_{i}' for i in range(6)]\n",
    "\n",
    "detector = LSTMAutoencoder(\n",
    "    n_timesteps=10, \n",
    "    n_features=len(feature_columns)\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Load and train on normal data\n",
    "    normal_data = load_data(NORMAL_DATA_PATH, feature_columns)\n",
    "    detector.train(normal_data)\n",
    "    \n",
    "    # Detect anomaly robot joint\n",
    "    anomaly_data = load_data(ANOMALY_DATA_PATH, feature_columns)\n",
    "    anomalies = detector.detect_anomalies(anomaly_data)\n",
    "    \n",
    "    print(f\"Detected {anomalies.sum()} anomalies out of {len(anomalies)} sequences\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01c5111a2c7b8b3e2e3f53415dc61224cf3e7919bb90c4d6f1d95d6d1e96e383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
